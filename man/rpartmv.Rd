% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rpartmv.R
\name{rpartmv}
\alias{rpartmv}
\title{Recursive Partitioning and Regression Trees}
\usage{
rpartmv(
  formula,
  data = NULL,
  weights,
  subset,
  na.action = na.rpartmv,
  method,
  dissim,
  model = FALSE,
  x = FALSE,
  y = TRUE,
  parms,
  control,
  cost,
  ...
)
}
\arguments{
\item{formula}{A formula, as in the \code{lm} function.}

\item{data}{An optional data frame in which to interpret the variables named
in the formula.}

\item{weights}{Optional case weights.}

\item{subset}{Optional expression saying that only a subset of the rows of
the data should be used in the fit.}

\item{na.action}{The default action deletes all observations for which
\code{y} is missing, but keeps those in which one or more predictors are
missing.}

\item{method}{One of \code{"anova"}, \code{"poisson"}, \code{"class"},
\code{"mrt"}, \code{"dist"}, or \code{"exp"}. If \code{method} is missing
then the routine tries to make an intelligent guess. If \code{y} is a
survival object, then \code{method="exp"} is assumed, if \code{y} is a matrix
then \code{method="mrt"} is assumed, if \code{y} is a factor then
\code{method="class"} is assumed, otherwise \code{method="anova"}.is assumed.
It is wisest to specifiy the method directly, especially as more criteria are
added to the function. For method=\code{"dist"} the response must be a square
symmetric distance matrix; e.g. returned by \code{gdist} or
\code{xdiss}. Weights and cross-validation are currently not
implemented for method=\code{"dist"}. Alternatively, \code{method} can be a
list of functions named \code{init}, \code{split} and \code{eval}.}

\item{dissim}{Used when method=\code{"anova"} or method=\code{"mrt"}.
Dissimilarity types are either \code{"euc"} for Euclidean (sums of squares
about the mean) or \code{"man"} for Manhattan (sums of absolute deviations
about the mean. The latter is experimental and has proved useful for
ecological data.}

\item{model}{Keep a copy of the model frame in the result. If the input value
for \code{model} is a model frame (likely from an earlier call to the
\code{rpartmv} function), then this frame is used rather than constructing new
data.}

\item{x}{Keep a copy of the \code{x} matrix in the result.}

\item{y}{Keep a copy of the dependent variable in the result.}

\item{parms}{Optional parameters for the splitting function. Anova splitting
has no parameters. Poisson splitting has a single parameter, the coefficient
of variation of the prior distribution on the rates. The default value is 1.
Exponential splitting has the same parameter as Poisson. For classification
splitting, the list can contain any of: the vector of prior probabilities
(component \code{prior}), the loss matrix (component \code{loss}) or the
splitting index (component \code{split}). The priors must be positive and sum
to 1.  The loss matrix must have zeros on the diagonal and positive
off-diagonal elements. The splitting index can be \code{gini} or
\code{information}. The default priors are proportional to the data counts,
the losses default to 1, and the split defaults to \code{gini}.}

\item{control}{Options that control details of the \code{rpart} algorithm.}

\item{cost}{A vector of non-negative costs, one for each variable in the
model. Defaults to one for all variables.  These are scalings to be
applied when considering splits, so the improvement on splitting on a
variable is divided by its cost in deciding which split to choose.}

\item{...}{Arguments to \code{rpartmv.control} may also be specified in the
call to \code{rpartmv}.  They are checked against the list of valid arguments.}
}
\value{
An object of class \code{rpartmv}; a superset of a classification
tree.
}
\description{
Fit an \code{rpartmv} model.
}
\details{
This function is a clone of a previous version of function rpart
from standard package rpart. It is used here because it features multivariate
regression tree as an option (\code{method = "mrt"}). This option has been
made unavailable from the standard rpart implementation, but required by
mvpart.
}
\examples{
## Load the car data set:
data("car.test.frame")

## Estimating a regression tree with a single descriptor:
rt.auto1 <- rpartmv(Mileage ~ Weight, data=car.test.frame)

## Print the model:
rt.auto1

## Summarize the model:
summary(rt.auto1)

## Plotting the model:
par(mar=c(1,1,1,1))
plot(rt.auto1)

## Showing the tree labels
text(rt.auto1)

## Load the spider data set:
data(spider)

## Splitting the table into the responses (species, Y)
## and the descriptors (X):
Y <- data.matrix(spider[,1L:12L])
X <- spider[,13L:18L]
## Note: the multivariate response needs to be processed proceed using
## function data.matrix before being used as a multivariate response by
## function rpartmv.

## Estimating a multivariate regression tree with multiple descriptors:
rt.spider1 <- rpartmv(Y ~ water + twigs + reft + herbs + moss + sand,
                      data = X, method="mrt")

## Summarized the multivariate regression tree
summary(rt.spider1)

## Plotting the model with the labels
par(mar=c(1,1,1,1))
plot(rt.spider1)
text(rt.spider1)

## Estimating a multivariate regression tree, using the Manhattan
## dissimilarity metric, with multiple descriptors
rt.spider2 <- rpartmv(Y ~ water + twigs + reft + herbs + moss + sand,
                      data = X, method="mrt", dissim="man")

## Summarized the multivariate regression tree
summary(rt.spider2)

## Plotting the model with the labels
par(mar=c(1,1,1,1))
plot(rt.spider2)
text(rt.spider2)

## Transforming the response on the basis of the Bray-Curtis dissimilarity:
Y_bray <- gdist(spider[,1L:12L], method="bray", full=TRUE, sq=TRUE)

## Estimating a multivariate regression tree, using method "dist"
rt.spider3 <- rpartmv(Y_bray ~ water + twigs + reft + herbs + moss + sand,
                      data = X, method="dist")

## Summarized the multivariate regression tree
summary(rt.spider3)

## Plotting the model with the labels
par(mar=c(1,1,1,1))
plot(rt.spider3)
text(rt.spider3)

### Fitted values and predictions:

## Obtain the fitted values and residuals:
pred.auto1 <- predict(rt.auto1)
res.auto1 <- residuals(rt.auto1)

## Plotting the fitted car mileage with respect to the observed values:
rng <- range(car.test.frame$Mileage, pred.auto1)  ## Same range.

par(mar=c(4.25,4.25,1.25,1.25))
plot(x = car.test.frame$Mileage, y = pred.auto1, xlim=rng, ylim=rng, asp=1)
abline(0,1)

rng <- max(abs(res.auto1))*c(-1,1)  ## Symmetric range for the residuals
plot(x = pred.auto1, y = res.auto1, ylim=rng, xlab="Fitted",
     ylab="Residuals")
abline(h=0, lty=3L)

## A classification tree using a binary response variable:
data(kyphosis)
Kyp1 <- rpartmv(Kyphosis ~ Age + Number + Start, data=kyphosis)

## Predictions as class probabilities (the default):
Kyp1.prob <- predict(Kyp1, type="prob")
plot(x = kyphosis$Kyphosis, y = Kyp1.prob[,"present"])

## Predictions as level numbers:
par(mar=c(4.25,4.25,1.25,4.25))
Kyp1.vect <- predict(Kyp1, type="vector")
plot(x = kyphosis$Kyphosis, y = as.factor(Kyp1.vect))

## Predictions as factors
Kyp1.fact <- predict(Kyp1, type="class")
plot(x = kyphosis$Kyphosis, y = Kyp1.fact)

## Predictions as level number, class frequencies, and probabilities:
Kyp1.matr <- predict(Kyp1, type="matrix")
head(Kyp1.matr, n=10L)  ## The first ten predictions

## Example of external validation using a subset:
data(iris)

set.seed(1234567L)

iris.sub <- c(sample(1L:50L, 25L),sample(51L:100L,25L),sample(101L:150L,25L))
iris1 <- rpartmv(Species ~ ., data=iris, subset=iris.sub)

iris1.out <- predict(iris1, iris[-iris.sub,], type="class")

table(iris1.out, iris[-iris.sub, "Species"])

## Regression examples with mostly categorical descriptors:
data(solder)
solder1 <- rpartmv(skips ~ Opening + Solder + Mask + PadType + as.factor(Panel),
                   data = solder, method="anova")

solder1

summary(solder1)

solder1.fit <- predict(solder1)
solder1.res <- residuals(solder1)

rng <- max(abs(solder1.res))*c(-1,1)  ## Symmetric range for the residuals
plot(x = solder1.fit, y = solder1.res, ylim=rng, xlab="Fitted",
     ylab="Residuals")
abline(h=0, lty=3L)

## R-square plots:
rsq(rt.auto1)
rsq(Kyp1)
rsq(rt.spider1)
rsq(rt.spider2)
## rsq(rt.spider3)  ## Won't work for method = "dist"
rsq(iris1)
rsq(solder1)

## Mean and variance plots (for regression trees only):
meanvar(rt.auto1)
meanvar(solder1)

}
\references{
Breiman, Friedman, Olshen, and Stone. (1984) Classification and Regression
Trees. Wadsworth.

De'ath G. (2002) Multivariate Regression Trees : A New Technique for
Constrained Classification Analysis. Ecology 83(4): 1103-1117.
}
\seealso{
\code{\link{rpartmv.control}}, \code{\link{rpartmv-class}}, and
\code{\link{gdist}}
}
\keyword{multivariate}
